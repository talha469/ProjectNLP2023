{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dshx_vPDQtdM",
        "outputId": "106e9369-5ec6-439a-c0c9-36b0dafb9198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 30 words from ebook_1: ['little', 'thee', 'like', 'thou', 'thy', 'love', 'sweet', 'night', 'joy', 'away', 'weep', 'father', 'sleep', 'happy', 'shall', 'day', 'mother', 'child', 'every', 'never', 'thel', 'hear', 'green', 'voice', 'infant', 'see', 'human', 'cloud', 'lamb', 'till']\n",
            "Book Title: Poems by William Blake 1789 little\n",
            "Chapter Titles: ['SONGS OF INNOCENCE', 'THE SHEPHERD', 'THE ECHOING GREEN']\n",
            "Jaccard Similarity between the Top 30 Words and the Book Title: 0.03\n",
            "Title:SONGS OF INNOCENCE: 0.00\n",
            "Title:THE SHEPHERD: 0.00\n",
            "Title:THE ECHOING GREEN: 0.03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word to book similarities: {}\n",
            "{'little': {}, 'thee': {}, 'like': {}, 'thou': {}, 'thy': {}, 'love': {}, 'sweet': {}, 'night': {}, 'joy': {}, 'away': {}, 'weep': {}, 'father': {}, 'sleep': {}, 'happy': {}, 'shall': {}, 'day': {}, 'mother': {}, 'child': {}, 'every': {}, 'never': {}, 'thel': {}, 'hear': {}, 'green': {}, 'voice': {}, 'infant': {}, 'see': {}, 'human': {}, 'cloud': {}, 'lamb': {}, 'till': {}}\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Question 2:We want to evaluate the extent to which these common wordings are\n",
        "linked to the title of the book and/or its chapter titles. Write a script that\n",
        "calculates i) the Jaccard distance between each word (among the thirty\n",
        "frequent words) and title; and between the word and each of chapter title,\n",
        "ii) Resnik semantic similarity measure\n",
        "(available in NLTK https://www.nltk.org/howto/wordnet.html ) of each word\n",
        "with title; and Resnik semantic similarity of each word with each chapter\n",
        "title (use the semantic similarity between sentences as experienced in\n",
        "the laboratory session but with Resnik similarity metric). Note that\n",
        "to utilize Resnik semantic similarity, you need to provide a corpus\n",
        "to calculate the information content. For this purpose, you use the\n",
        "whole Gutenberg as a corpus (see examples in NLTK online book)\n",
        "Summarize the results in a table.\n",
        "\n",
        "\n",
        "# For Jaccard Similarity\n",
        "# Already: We already have the 30 most used words inside the book and now we want to get the analysis between\n",
        "# Let's save the top 30 words with frequencies.\n",
        "\n",
        "i) the 30 words and the title of the book\n",
        "\n",
        "\n",
        "\n",
        "ii) the 30 words and the each chapter of the book\n",
        "\n",
        "\n",
        "# For Resnik Semantic Similarity\n",
        "# Already: We already have the 30 most used words inside the book and now we want to get the analysis between\n",
        "i) the 30 words and the title of the book\n",
        "ii) the 30 words and the each chapter of the book\n",
        "\n",
        "Note! For Resnik Semantic we need to create information content: For this we can use the whole Gutenberg as a corpus.\n",
        "\n",
        "Finally: You need to summarize the results in a table.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "top_30_words_ebook_1=[('little', 45), ('thee', 42), ('like', 35), ('thou', 35), ('thy', 31), ('love', 29), ('sweet', 28), ('night', 28), ('joy', 25), ('away', 24), ('weep', 24), ('father', 22), ('sleep', 21), ('happy', 19), ('shall', 19), ('day', 19), ('mother', 19), ('child', 18), ('every', 17), ('never', 17), ('thel', 16), ('hear', 16), ('green', 16), ('voice', 16), ('infant', 16), ('see', 16), ('human', 16), ('cloud', 15), ('lamb', 15), ('till', 15)]\n",
        "\n",
        "top_30_words_ebook_2=[('emma', 855), ('could', 836), ('would', 818), ('miss', 599), ('must', 566), ('harriet', 496), ('much', 484), ('said', 483), ('one', 447), ('every', 435), ('weston', 430), ('thing', 394), ('think', 383), ('well', 378), ('elton', 378), ('knightley', 373), ('little', 359), ('never', 358), ('know', 335), ('might', 325), ('good', 313), ('say', 310), ('woodhouse', 308), ('jane', 301), ('quite', 282), ('time', 275), ('great', 263), ('nothing', 252), ('dear', 241), ('always', 238)]\n",
        "# Jaccard similarity.\n",
        "top_30_words_ebook_1 = [w[0] for w in top_30_words_ebook_1]\n",
        "top_30_words_ebook_2 = [w[0] for w in top_30_words_ebook_2]\n",
        "\n",
        "# Let me pause the and write the remaining code first.\n",
        "from nltk.metrics import jaccard_distance\n",
        "\n",
        "# Define the top 30 frequent words in ebook_1\n",
        "top_30_words_ebook_1 = ['little', 'thee', 'like', 'thou', 'thy', 'love', 'sweet', 'night', 'joy', 'away',\n",
        "                'weep', 'father', 'sleep', 'happy', 'shall', 'day', 'mother', 'child', 'every',\n",
        "                'never', 'thel', 'hear', 'green', 'voice', 'infant', 'see', 'human', 'cloud', 'lamb', 'till']\n",
        "\n",
        "# Define the book title and chapter titles\n",
        "book_title = 'Poems by William Blake 1789 little'\n",
        "# I have taken some of the chapter titles\n",
        "chapter_titles = [\"SONGS OF INNOCENCE\", \"THE SHEPHERD\", \"THE ECHOING GREEN\"]\n",
        "\n",
        "print(f\"Top 30 words from ebook_1: {top_30_words_ebook_1}\")\n",
        "print(f\"Book Title: {book_title}\")\n",
        "print(f\"Chapter Titles: {chapter_titles}\")\n",
        "\n",
        "# Convert the list of words and book title\n",
        "word_set = set(top_30_words_ebook_1)\n",
        "title_set = set(book_title.lower().split())  # Convert to lowercase and split\n",
        "\n",
        "# Calculate Jaccard similarity between the sets\n",
        "jaccard_similarity = len(word_set.intersection(title_set)) / len(word_set.union(title_set))\n",
        "\n",
        "# Print the Jaccard similarity\n",
        "print(f\"Jaccard Similarity between the Top 30 Words and the Book Title: {jaccard_similarity:.2f}\")\n",
        "\n",
        "# Now lets Check the similarity between the words and each chapter of the book.\n",
        "\n",
        "\n",
        "for title in chapter_titles:\n",
        "    title_set = set(title.lower().split())\n",
        "    # Calculate Jaccard similarity between the sets\n",
        "    jaccard_similarity = len(word_set.intersection(title_set)) / len(word_set.union(title_set))\n",
        "\n",
        "    # Print the Jaccard similarity\n",
        "    print(f\"Title:{title}: {jaccard_similarity:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Now let's do the Rensik similarity:\n",
        "# It uses the wordnet in the background and what it does it get the most common ancertor in between the words or if we can see the single word then as well.\n",
        "# Then we can use the lemma will give me the word only.\n",
        "# and also we can get the definition of the word as well and we can also check the examples for that one as well. like how it is using inside the sentence.\n",
        "# We can also get the sysnomyns and antonyms of the word through the wordnet.\n",
        "# Lemma will give you the simple word instead of the dots in them.\n",
        "# Also we can use semantic search how similar the word is with out word which has been passed.\n",
        "# Rensik Similarity first check the corpus and then we give two words and then it will tell you the difference between them.\n",
        "from nltk.corpus import wordnet_ic\n",
        "from nltk.wsd import lesk\n",
        "from nltk.corpus import gutenberg\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus.reader import NOUN\n",
        "import nltk\n",
        "nltk.download('wordnet_ic')\n",
        "nltk.download('wordnet')\n",
        "# Load the Gutenberg corpus as the information content\n",
        "gutenberg_ic = wordnet_ic.ic('ic-brown.dat')\n",
        "# print(gutenberg_ic)\n",
        "# Information Content (IC): Information content is a measure of how specific or informative a word or concept is.\n",
        "#In the context of WordNet, IC is often based on word frequencies in a large corpus, which indicates how commonly\n",
        "#a word is used in natural language. More specific and less common words have higher IC values,\n",
        "#while more general and common words have lower IC values.\n",
        "# in the synset when compareing the two words we need to make sure that it is of same POS(Parts of Speech)\n",
        "# Function to calculate Resnik semantic similarity between a word and a sentence\n",
        "def calculate_resnik_similarity(word1, word2, ic):\n",
        "#     print(f\"Word1:{word1} Word2:{word2}\")\n",
        "    synset1 = wordnet.synsets(word1, pos=NOUN)\n",
        "    synset2 = wordnet.synsets(word2, pos=NOUN)\n",
        "#     print(synset1)\n",
        "#     print(synset2)\n",
        "    if synset1 and synset2:\n",
        "        similarity = synset1[0].res_similarity(synset2[0], ic)\n",
        "        print(similarity)\n",
        "        return similarity\n",
        "    return None\n",
        "\n",
        "word_to_book_similarities = {}\n",
        "for word in top_30_words_ebook_1:\n",
        "    similarity = calculate_resnik_similarity(word, book_title, gutenberg_ic)\n",
        "    if similarity is not None:\n",
        "        word_to_book_similarities[word] = similarity\n",
        "print(f\"Word to book similarities: {word_to_book_similarities}\")\n",
        "\n",
        "\n",
        "word_to_chapter_similarities = {}\n",
        "for word in top_30_words_ebook_1:\n",
        "    word_similarities = {}\n",
        "    for chapter in chapter_titles:\n",
        "        similarity = calculate_resnik_similarity(word, chapter, gutenberg_ic)\n",
        "        if similarity is not None:\n",
        "            word_similarities[chapter] = similarity\n",
        "    word_to_chapter_similarities[word] = word_similarities\n",
        "\n",
        "print(word_to_chapter_similarities)\n"
      ]
    }
  ]
}